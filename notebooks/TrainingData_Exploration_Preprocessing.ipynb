{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TrainingData_Exploration_Preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNGKQhGVp6V8+pb1ILLvuQm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckVURrW_V0aQ","executionInfo":{"status":"ok","timestamp":1650960932777,"user_tz":-120,"elapsed":17434,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"74b1a349-5811-4de4-d04f-a0b934918cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd \n","import numpy as np\n","import matplotlib.pyplot as plt \n","import seaborn as sns \n","import re \n","import nltk\n","# !pip install contractions\n","import contractions\n","\n","# !pip install textblob\n","from textblob import TextBlob\n","\n","# !pip install emot\n","import re\n","import pickle\n","\n","# !pip install inflect\n","import inflect\n","\n","import string\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**Data Exploration and Preprocessing**\n","\n","Below is the annotated dataset of tweets for the OffensEval competition: Identifying and Categorizing Offensive Language in Social Media. \n","\n","Twitter user names are substituted by @USER and IRLs by word URL. \n","\n","In this assignment we focus on subtask_a which indicates whether a Tweet has been annotated as offensive or not. Two labels are present: \n","\n","- **(NOT)** Not Offensive - This post does not contain offense or profanity.\n","- **(OFF)** Offensive - This post contains offensive language or a targeted (veiled or direct) offense.\n","\n","A Tweet is labeled as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct."],"metadata":{"id":"HlXMp0pPXwFX"}},{"cell_type":"code","source":["data_path = 'drive/MyDrive/NLP_Final_Assignment/data/olid-training-v1.0.tsv'\n","\n","df = pd.read_csv(data_path, sep='\\t', header=0)"],"metadata":{"id":"Mvf3KLTLWUwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"OTb-itugXpg7","executionInfo":{"status":"ok","timestamp":1650960938085,"user_tz":-120,"elapsed":6,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"5b24490c-265d-4a04-a5bd-0b87610f74aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      id                                              tweet subtask_a  \\\n","0  86426  @USER She should ask a few native Americans wh...       OFF   \n","1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n","2  16820  Amazon is investigating Chinese employees who ...       NOT   \n","3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n","4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n","\n","  subtask_b subtask_c  \n","0       UNT       NaN  \n","1       TIN       IND  \n","2       NaN       NaN  \n","3       UNT       NaN  \n","4       NaN       NaN  "],"text/html":["\n","  <div id=\"df-8396fad7-ce18-4c67-9c1d-418eb5d0e8ff\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>subtask_a</th>\n","      <th>subtask_b</th>\n","      <th>subtask_c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>86426</td>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>OFF</td>\n","      <td>UNT</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>90194</td>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>OFF</td>\n","      <td>TIN</td>\n","      <td>IND</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16820</td>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>NOT</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62688</td>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>OFF</td>\n","      <td>UNT</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>43605</td>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>NOT</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8396fad7-ce18-4c67-9c1d-418eb5d0e8ff')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8396fad7-ce18-4c67-9c1d-418eb5d0e8ff button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8396fad7-ce18-4c67-9c1d-418eb5d0e8ff');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df = df.drop(['subtask_b',\t'subtask_c'], 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60NdpMbQ7IQg","executionInfo":{"status":"ok","timestamp":1650960939347,"user_tz":-120,"elapsed":1,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"248e23c4-1829-4463-bade-0e922cb1ad96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","source":["# Change labels to binary digits\n","df_labels = pd.get_dummies(df[\"subtask_a\"]).drop('NOT', 1)\n","df = pd.concat((df, df_labels), axis = 1)\n","df = df.drop('subtask_a', 1).rename(columns={\"OFF\": \"offensive\"})\n","\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"sae1XDsI6-5P","executionInfo":{"status":"ok","timestamp":1650960939755,"user_tz":-120,"elapsed":5,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"1cf1468e-2f3a-4dd3-df56-60aa5d515aaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n","  after removing the cwd from sys.path.\n"]},{"output_type":"execute_result","data":{"text/plain":["      id                                              tweet  offensive\n","0  86426  @USER She should ask a few native Americans wh...          1\n","1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...          1\n","2  16820  Amazon is investigating Chinese employees who ...          0\n","3  62688  @USER Someone should'veTaken\" this piece of sh...          1\n","4  43605  @USER @USER Obama wanted liberals &amp; illega...          0"],"text/html":["\n","  <div id=\"df-85ae0970-b30b-49a1-aae4-fddc30ecbefb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>tweet</th>\n","      <th>offensive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>86426</td>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>90194</td>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>16820</td>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>62688</td>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>43605</td>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85ae0970-b30b-49a1-aae4-fddc30ecbefb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-85ae0970-b30b-49a1-aae4-fddc30ecbefb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-85ae0970-b30b-49a1-aae4-fddc30ecbefb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Dataset unique per tweet? \n","print(\"Number of unique id's: \" , str(df['id'].nunique()))\n","print(\"Number of rows: \" , str(len(df)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbK29t3jcd19","executionInfo":{"status":"ok","timestamp":1650960940568,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"6d558da8-5327-4ab7-e8fe-d0aa7403e906"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique id's:  13240\n","Number of rows:  13240\n"]}]},{"cell_type":"code","source":["duplicated = df[df.duplicated()]\n","duplicated\n","\n","# drop duplicates\n","df = df.drop_duplicates()\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YY1VjMtUGbnf","executionInfo":{"status":"ok","timestamp":1650960941756,"user_tz":-120,"elapsed":3,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"79761db2-2034-47e0-cdec-bf5adc319b79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(13212, 2)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Set id as index, keep only text and label\n","df = df.set_index('id')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"F_KWFn4w7gBP","executionInfo":{"status":"ok","timestamp":1650960941348,"user_tz":-120,"elapsed":3,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"4385a00b-8e87-424f-f5b9-2b6142ca9fe9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   tweet  offensive\n","id                                                                 \n","86426  @USER She should ask a few native Americans wh...          1\n","90194  @USER @USER Go home you’re drunk!!! @USER #MAG...          1\n","16820  Amazon is investigating Chinese employees who ...          0\n","62688  @USER Someone should'veTaken\" this piece of sh...          1\n","43605  @USER @USER Obama wanted liberals &amp; illega...          0"],"text/html":["\n","  <div id=\"df-edead515-40f2-4349-a01d-ac1f1018d569\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>offensive</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>86426</th>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>90194</th>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16820</th>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>62688</th>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>43605</th>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edead515-40f2-4349-a01d-ac1f1018d569')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-edead515-40f2-4349-a01d-ac1f1018d569 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-edead515-40f2-4349-a01d-ac1f1018d569');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["\n","\n","Below an example of first 20 tweets from the dataset:"],"metadata":{"id":"c5L1e7kZer1b"}},{"cell_type":"code","source":["df.tweet[0:20].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zO-biG4sXseG","executionInfo":{"status":"ok","timestamp":1650960942478,"user_tz":-120,"elapsed":7,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"e89a0bf5-64d0-426a-e7d9-58fbfaeca5ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@USER She should ask a few native Americans what their take on this is.',\n","       '@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL',\n","       'Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT',\n","       '@USER Someone should\\'veTaken\" this piece of shit to a volcano. 😂\"',\n","       '@USER @USER Obama wanted liberals &amp; illegals to move into red states',\n","       '@USER Liberals are all Kookoo !!!',\n","       '@USER @USER Oh noes! Tough shit.',\n","       '@USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism',\n","       '@USER Buy more icecream!!!',\n","       '@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo',\n","       '@USER @USER @USER It’s not my fault you support gun control',\n","       '@USER What’s the difference between #Kavanaugh and @USER   One of these men admitted to groping a 15 year old girl years ago.  The other is going to be #confirmed to the SCJ   #DemsareFrauds #DemsAreDone   #WalkAwayDemocrats2018 #redwave #VoteRedSaveAmerica #trumptrain #MAGA URL',\n","       '@USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL',\n","       '@USER @USER @USER It should scare every American!  She is playing Hockey with a warped puck!',\n","       '@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER I like my soda like I like my boarders with a lot of ICE.',\n","       '@USER you are also the king of taste',\n","       \"#MAGA @USER  🎶 Sing like no one is listening  ♥️ Love like you've never been hurt  ✔️ Vote GOP when no one is watching  🙉  And don't listen to Liberals' dirt URL\",\n","       '5/5: @USER The time is right for this House to respond to the concerns of all Canadians. Four out of five Canadians support stronger gun control and with good reason.” #guncontrol #cdnpoli #cdnhist\"',\n","       '@USER Besides Jax’s mom and maybe Ope he is hands down my favorite he’s like the only good person on the show 😂',\n","       '@USER @USER @USER gun control! That is all these kids are asking for!'],\n","      dtype=object)"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["Tweets include @USER and URL which could be taken out or left in. These two might be useful for model to detect the direction of the offense but are not necessary to detect the presence of offensive language. However, keeping them in could also help with detecting POS which can be used to improve the model detecting offensive language, so we'll keep them in. Removing them may make some sentences weird.\n","\n","Tweets also include emojis and hashtags which should be dealt with. Hashtags can be cleaned by removing '#' and including them as words in the dataset. Emojis will be translated into words during text pre-processing. \n","\n","Moreover, there are other aspects of text cleaning and normalization which need evaluating for this project: extra whitespace, special characters, upper-lowercase characters, repetitions of letters (e.g. Hiiiiii instead of Hi) and contractions ('don't', 'yall').\n","\n","Finally, there are some cases of self-censored words. Some users wrote f*uck or sh.t, using '.' or '\\*' to censor profanity. While human coders can understand this as offensive and code as such, this may be missed by models. So improving this in such way that self-censored words are fully represented could also improve the model. \n","\n","Below are some tweets which are coded offensive: \n"],"metadata":{"id":"qOezNuA_sdkc"}},{"cell_type":"code","source":["df[df['offensive'] == 1].tweet[100:120].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIZ5qV3-2k-a","executionInfo":{"status":"ok","timestamp":1650960943961,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"80a17c05-6362-4a2f-b9db-0317db08da49"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([\"@USER @USER @USER @USER I wasn't proposing scare tactics. I really meant what I said. Trump can easily pull the good maga Republicans and can easily steal enough votes from GOP Dem and independents and will bring fresh breath to our rotten politics. Think about it.\",\n","       '@USER @USER @USER @USER Only a liberal would support a liberal that spent a MILLION to get liberals elected to office. #LibFAIL! URL',\n","       '@USER It’s so weirdly vicious and bitter to extrapolate from ‘everyone should have access to decent healthcare’ to ‘Liberals think all criminals should be free.’  It reveals a pretty brutalist and impenetrable mind.',\n","       '@USER What the fuck game are you watching?',\n","       '@USER Why? Why are liberals so trashy?',\n","       '@USER Yes I saw this and I will say tapper kept basket her and she kept coming back with stupid answers And he finally gave up I don’t think he is a big fan of her policies he’s not that stupid please',\n","       '@USER If you go by anything other than he or she you are fucked in the head.',\n","       '@USER All you need to know is he is empty inside',\n","       '@USER The Liberals are mentally unstable!!',\n","       '@USER @USER Who authorized a search warrant of mr Jean home?  Racist what about her drug test. This is premediated murder. He will not be slandered. He is the victim.',\n","       '@USER @USER @USER i have heard he is making waves',\n","       '#ThursdayThoughts- FUCK liberals. Forever.',\n","       \"@USER Once again it's been proven that all gun control laws are intended to disarm the law abiding citizens and subvert the #2A. Criminal *don't* care about gun laws.\",\n","       '@USER @USER Mxm nigger thinks we give a fuck URL',\n","       '@USER @USER She is a fake. Vote her out. Now she wants sympathy.',\n","       '10kids from different women from this American jobless men? Nigerian men you are the bomb!!!',\n","       '@USER This Russian agent is a DISGRACE. Hey old creep @USER you are going to die in prison. You and Trump sold America to the Russians and it’s time you do the time for your years of crimes. Scumbag.',\n","       '@USER What insanely ridiculous bullshit.',\n","       '@USER We shouldn’t be surprised. These same pigs worked with neonazis to unmask antifa protestors. And the local coverage by shit journos like @USER didn’t cover that AT ALL. We had to rely on @USER for investigative coverage URL',\n","       '@USER @USER Because 45% of Americans are too lazy to vote.  Non-voters skew liberal. And too many liberals who do vote throw their vote away on 3rd party losers. Next question?'],\n","      dtype=object)"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["4400 tweets are tagged as offensive and 8840 tweets as not offensive. The dataset is not balanced. Balancing the dataset could be beneficial for the classification task but on the other hand the unbalanced dataset represent the reality as tweets including offensive content are not the majority of Twitter (Zampieri et al. 2019). Hence the dataset will not be balanced. "],"metadata":{"id":"HsirNpGx2Y_r"}},{"cell_type":"code","source":["df.offensive.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hyzigss1X8vm","executionInfo":{"status":"ok","timestamp":1650960944381,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"bf8cc789-b703-4bba-dcf7-4e2cfeb8daa9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    8817\n","1    4395\n","Name: offensive, dtype: int64"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["df.offensive.isnull().sum()\n","\n","# No missing values in the label, all tweets are coded for subtask A."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5qgn-hUcUWU","executionInfo":{"status":"ok","timestamp":1650960945102,"user_tz":-120,"elapsed":338,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"b6a74f0d-0021-4e00-cb8d-43f6ca348009"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Below I try to find the self-censored words to correct them. I do this before removing symbols or de-duplicating punctuation so that self-censored words can be found easily. The function below finds the words that begin and end with a letter but in between have some symbols that I have seen for self-censoring profanity. Some examples are printed below: "],"metadata":{"id":"StL3r2B7yfTG"}},{"cell_type":"code","source":["# create a function that finds words that begin and end with a letter but have \n","def selfcensored(sentence):    \n","    pattern = re.compile(r'[a-zA-Z]+[\\.\\*\\?!&^]{1,}[a-zA-Z]+')\n","    found = re.findall(pattern,sentence.lower())\n","    if found:\n","      return found\n","  \n","# for sent in df['tweet_clean']:\n","#   if selfcensored(sent) != None:\n","#       print(selfcensored(sent))\n","\n","\n","# list of self-censored profanity cases\n","  \n","list_selfcensored = ['f\\*\\*king', 'sh\\*t', 'p\\*\\*sy', 'f\\*cks', 'fu\\*k', \n","                     'f\\*cking', 'b\\*\\*ch', 'bullsh\\*t', 'f\\*ck', 'sh\\!t', \n","                     'f\\*\\*ked', 'f\\*\\*\\*ing', 'a\\*\\*hole', 'd\\*mbasses', 'da\\*n'\n","                     ]\n","\n"],"metadata":{"id":"hxH9QzWW2Q1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[df['tweet'].str.contains(r'[a-zA-Z]+[\\*]{1,}[a-zA-Z]+')][['tweet']].values[0:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vopk6dFd08XP","executionInfo":{"status":"ok","timestamp":1650960946472,"user_tz":-120,"elapsed":435,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"a48d23c9-a1c5-41a8-a330-5157360dc988"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo'],\n","       [\"@USER At this point in time... I don't think Pres. Trump gives a sh*t... and neither do I! LOL URL\"],\n","       ['@USER @USER Did Chuck think Juanita Broderick credible-Keith Ellison’s girlfriend domestic abuse credible? The truth is Chuck is a sh*t stirrer for a cause. In this case- ruin a mans impeccable career-embarrass his wife &amp; daughters-all in a sleazy days work. Y?Liberals destroy what dont like']],\n","      dtype=object)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Text preprocessing \n","\n","def expand_contractions(text):\n","    clean_text = contractions.fix(text)\n","    \n","    return clean_text\n","    \n","\n","def remove_punc(text):    # Removing special characters in string but keeping \n","                 # punctuations: \",.;:!?\" also * (bc of self-censored words) and\n","                 # @ because of referral to a user\n","  punc = '''()-[]{}'\"\\<>/#$%^&_~'''\n","\n","  for punctuation in punc:\n","    text = text.replace(punctuation, '')\n","  \n","  return text\n","\n","\n","def whitespace_be(text): # remove whitespace beginning and end of tweet due to cleaning\n","\n","  text = re.sub('^\\s+|\\s+$', '', text, flags=re.UNICODE)\n","\n","  return text\n","\n","def whitespace_double(text): # remove duplicate whitespace \n","  text = re.sub('\\s+', ' ', text, flags=re.UNICODE)\n","\n","  return text\n","\n","# Convert emojis into words\n","from emot.emo_unicode import UNICODE_EMOJI, EMOTICONS_EMO\n","\n","def convert_emojis(text):\n","    for emot in UNICODE_EMOJI:\n","        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n","    return text\n","\n","def clean_text(text):\n","    \n","    text = text.lower()\n","    \n","    text = expand_contractions(text)\n","        \n","    text = remove_punc(text)\n","    \n","    text = whitespace_be(text)  \n","\n","    text = whitespace_double(text)  \n","\n","    text = convert_emojis(text)\n","\n","    return text\n","\n","df['tweet_clean'] = df.apply(lambda x: clean_text(x['tweet']), axis=1)"],"metadata":{"id":"x0WrYOi_lu6F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['tweet_clean'].values[0:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vDl2lJqBPNUH","executionInfo":{"status":"ok","timestamp":1650961063368,"user_tz":-120,"elapsed":20,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"14bed16d-d50b-4b1f-b83c-811ab0913e7c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@user she should ask a few native americans what their take on this is.',\n","       '@user @user go home you are drunk!!! @user maga trump2020 oncoming_fistUnited_Statesoncoming_fist url',\n","       'amazon is investigating chinese employees who are selling internal data to thirdparty sellers looking for an edge in the competitive marketplace. url amazon maga kag china tcot',\n","       '@user someone shouldvetaken this piece of shit to a volcano. face_with_tears_of_joy',\n","       '@user @user obama wanted liberals amp; illegals to move into red states'],\n","      dtype=object)"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["Apparently only 23 tweets had self-censored words, 18 were labeled as offensive and it seems that they were labeled this way because of these words. While I expected there to be more, it is still good to correct this. 5 tweets with self-censored profanity seems to be labeled non-offensive which can be due to differences between annotators. "],"metadata":{"id":"7t6W8YQLY_IB"}},{"cell_type":"code","source":["df[df['tweet_clean'].str.contains('|'.join(list_selfcensored))]['offensive'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wznwef5XVXy2","executionInfo":{"status":"ok","timestamp":1650961072795,"user_tz":-120,"elapsed":327,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"526d18d8-ccaf-41fc-de8b-4cb325ac3764"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    18\n","0     5\n","Name: offensive, dtype: int64"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["checkOFF = df[(df['tweet_clean'].str.contains('|'.join(list_selfcensored))) & (df['offensive'] == 1)]\n","checkOFF.tweet.values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ek37XEI8Vyd7","executionInfo":{"status":"ok","timestamp":1650961076063,"user_tz":-120,"elapsed":344,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"65cd4b45-3232-4f60-8e26-701554eaa1ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo',\n","       \"@USER At this point in time... I don't think Pres. Trump gives a sh*t... and neither do I! LOL URL\",\n","       '@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Even pedophiles in interviews will tell you the only way to stop them is to kill them. Pedophiles even admit to when out of prison they will offend again and that’s what keeps them alive in prison... the hope of another opportunity to molest an innocent child. They are sick f*cks',\n","       \"@USER @USER This B**ch Behar needs to shut that big ugly hole on her face and think about the fact she's not giving Kavanaugh or his family the benefit of their rights as citizens. In her fat head they're guilty bc they're Conservatives. Behar needs a muzzle around decent people. HRC clone.\",\n","       '@USER @USER @USER @USER @USER ...how you want to be defined\"? PUL-EASE! When you live under a 24/7/365 MSMedia SHIT-SMEAR to the point you have Marxine Waters sending her ANTIFA minions out to threaten you in public places - you learn not to give a F*CK what the \"Pavlovian Left\" thinks. Night, night 🌙!\"',\n","       '@USER He is still eating and talking about p**sy on carter V. Trust me',\n","       '@USER @USER Liberals don’t give a sh!t. They have no souls.',\n","       '@USER @USER is a very lost soul! His father f**ked him up real good!',\n","       '@USER @USER So pointing at the umpire and calling him thief is berating and walking very fast toward an official and calling them f***ing moron is not? I think it is clear who needs help. You are a man perhaps?',\n","       \"@USER I hope that ENTIRE police department gets shut the f*ck down!Obviously you all feel like you're above the law.Obviously you are incapable of holding your OWN accountable for breaking the law.Obviously you undermine everything a police officer&amp;dept are SUPPOSED to be/do. Shameful!\",\n","       \"@USER @USER She is just spewing sh*t Bernie's robot what a lie they will say &amp; do anything and what she is going to do for district 14 not a da*n thing Socialism don't work that way they suck all up.\",\n","       '@USER Lolol God he is such an a**hole.',\n","       \"@USER Because Obama has zero accomplishments. He is the worst President r leader of any country hands down. It shows the liberal lunacy when they worship a total loser. They don't know what they want..no party goals. nothing except complain about TRUMPS accomplishments. Fu*k liberals.\",\n","       '@USER @USER @USER @USER @USER @USER @USER @USER @USER  Antifa unmasked and up close!Hey is that who I think it is??? p.s. They are SO STUPID no one told them a white raised fist stands for “White Power”so Thanks D*MBASSES! URL',\n","       \"@USER Go to hell! This is NOT Queen for a Day. I believe you less and less with every bit of bullsh*t you pull. You're nothing but a lying Demonrat! #MAGA #Trump2020\",\n","       '@USER @USER Communists: Liberals get the bullet, too.\"  Me: \"Wow f*ck you!\"  Communists: \"You are excluding instead of unifying.\"\"',\n","       '@USER You are obsessed with @USER  She’s a millionaire because she is a good comedian. You have money because Big Daddy Bone Spurs handed it to you a**hole.',\n","       \"@USER @USER Why didn't Zac Goldsmith of the faux Conservative Party use this?  Why didn't faux Conservative Party use Khan's defence of 9/11 organiser?  Why are the Conservatives so f*cking useless? If you ask me it's deliberate as they share Labour's agenda or are they just that useless?\"],\n","      dtype=object)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["checkNOT = df[(df['tweet_clean'].str.contains('|'.join(list_selfcensored))) & (df['offensive'] == 0)]\n","checkNOT.tweet.values\n","# I dont know why these tweets are not marked as , they seem offensive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDrEgVfW9umK","executionInfo":{"status":"ok","timestamp":1650961076064,"user_tz":-120,"elapsed":10,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"b4b3f0fb-f4d9-454a-9dbb-464352b4d0e6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['@USER @USER Did Chuck think Juanita Broderick credible-Keith Ellison’s girlfriend domestic abuse credible? The truth is Chuck is a sh*t stirrer for a cause. In this case- ruin a mans impeccable career-embarrass his wife &amp; daughters-all in a sleazy days work. Y?Liberals destroy what dont like',\n","       '2/2 More from Mark Judge,Kavanaugh\\'s bro:liberals are trying to take our fun away... Brent Musburger can’t call a hot girl hot... Obama wants to outlaw guns because it’s all about the children.The children,the children...No one can belch because of the f*cking children\" URL',\n","       '@USER @USER Conservatives characterize an attempted rape allegation as “bullsh*t” then wonder why liberals describe them as anti-woman.  The right thing to do is properly investigate the allegation. If she lying then prosecute her. If she’s telling the truth Kavanaugh shouldn’t be confirmed.',\n","       '@USER She is really good for him and told him how he needed to straighten up. I like her and I like them together. Sometimes you just need someone who calls you out on your sh*t so you can become a better person 💖',\n","       '@USER @USER Looks like gun control is working out well for your sh*t hole country huh?  How are those gun laws working huh? More shootings and murders by gun than America which has more guns than people in Brazil'],\n","      dtype=object)"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["It seems that indeed most words in the self-censored list are labeled as offensive. There was cases where f\\*cking and sh\\*t was labeled as not offensive\n","but I will correct these words because mostly they are taken as offensive by \n","the annotators.\n","\n","Before cleaning these manually, I tried a spelling corrector (TextBlob) to see if these will be corrected by the spelling corrector. However this did not work, so I changed the words in the list manually before applying the spelling corrector. "],"metadata":{"id":"uSZsHX3bAL0r"}},{"cell_type":"code","source":["# change self-censored words\n","list_selfcensored = ['f\\*\\*king', 'sh\\*t', 'p\\*\\*sy', 'f\\*cks', 'fu\\*k', \n","                     'f\\*cking', 'b\\*\\*ch', 'bullsh\\*t', 'f\\*ck', 'sh\\!t', \n","                     'f\\*\\*ked', 'f\\*\\*\\*ing', 'a\\*\\*hole', 'd\\*mbasses', \n","                     'da\\*n']\n","\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('f\\*\\*king','fucking', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('sh\\*t','shit', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('p\\*\\*sy','pussy', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('f\\*cks','fucks', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('fu\\*k','fuck', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('f\\*cking','fucking', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('b\\*\\*ch','bitch', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('bullsh\\*t','bullshit', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('f\\*ck','fuck', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('sh\\!t','shit', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('f\\*\\*ked','fucked', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('f\\*\\*\\*ing','fucking', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('a\\*\\*hole','asshole', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('d\\*mbasses','dumbasses', x, flags=re.UNICODE))\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub('da\\*n','damn', x, flags=re.UNICODE))\n","\n","# finally remove *\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub(r'\\*','', x, flags=re.UNICODE))"],"metadata":{"id":"XzxrXyHyxIZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# how does it seem now\n","\n","df[df['tweet'].str.contains('|'.join(list_selfcensored))][['tweet', 'tweet_clean']].values[0:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xt-v3XWzZvoH","executionInfo":{"status":"ok","timestamp":1650961076887,"user_tz":-120,"elapsed":2,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"60be5610-a90e-4fbc-8686-8263cfa26f9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo',\n","        '@user canada does not need another cuck! we already have enough looneyleft liberals fucking up our great country! qproofs trudeaumustgo'],\n","       [\"@USER At this point in time... I don't think Pres. Trump gives a sh*t... and neither do I! LOL URL\",\n","        '@user at this point in time... i do not think pres. trump gives a shit... and neither do i! lol url'],\n","       ['@USER @USER Did Chuck think Juanita Broderick credible-Keith Ellison’s girlfriend domestic abuse credible? The truth is Chuck is a sh*t stirrer for a cause. In this case- ruin a mans impeccable career-embarrass his wife &amp; daughters-all in a sleazy days work. Y?Liberals destroy what dont like',\n","        '@user @user did chuck think juanita broderick crediblekeith ellison’s girlfriend domestic abuse credible? the truth is chuck is a shit stirrer for a because. in this case ruin a mans impeccable careerembarrass his wife amp; daughtersall in a sleazy days work. y?liberals destroy what do not like']],\n","      dtype=object)"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# de-duplicating punctuations\n","def my_replacer(match):\n","    match = match.group()\n","    return match[0] + (\" \" if \" \" in match else \"\")\n","\n","regex = r\"[\\.\\?\\!]{2,}\"\n","\n","df['tweet_clean'] = df.tweet_clean.apply(lambda x: re.sub(regex, my_replacer, x, 0))\n","\n","df[df['tweet'].str.contains(r'[\\.\\?\\!]{2,}')][['tweet', 'tweet_clean']].values\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qQnhDIvvL9P","executionInfo":{"status":"ok","timestamp":1650961078539,"user_tz":-120,"elapsed":349,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"211ae048-717b-4401-d30f-7fe40379ce29"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL',\n","        '@user @user go home you are drunk! @user maga trump2020 oncoming_fistUnited_Statesoncoming_fist url'],\n","       ['@USER Liberals are all Kookoo !!!',\n","        '@user liberals are all kookoo !'],\n","       ['@USER Buy more icecream!!!', '@user buy more icecream!'],\n","       ...,\n","       ['@USER @USER @USER @USER Right. Dang. She is the s...t',\n","        '@user @user @user @user right. dang. she is the s.t'],\n","       ['@USER @USER @USER So have the conservatives accepted the antisemitism definition yet?..',\n","        '@user @user @user so have the conservatives accepted the antisemitism definition yet?'],\n","       ['@USER @USER BUT GUN CONTROL!!!', '@user @user but gun control!']],\n","      dtype=object)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# apply spelling check - takes way too long\n","# df['tweet_clean'] = df.tweet_clean.apply(lambda txt: ''.join(TextBlob(txt).correct()))"],"metadata":{"id":"L69Vj80vBPyF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dealing with emojis**\n","\n","In the last step of text preprocessing, emoji's were translated into words to be able to take them into account as well. We check how this looks like:"],"metadata":{"id":"0-JWIembhMZj"}},{"cell_type":"code","source":["# Convert emojis into words\n","from emot.emo_unicode import UNICODE_EMOJI\n","\n","def convert_emojis(text):\n","    for emot in UNICODE_EMOJI:\n","        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n","    return text\n","\n","df['tweet_clean'] = df.tweet_clean.apply(lambda txt: convert_emojis(txt))\n"],"metadata":{"id":"WqCwdgMKomRp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Below we can see that the emojis are turned into word representations"],"metadata":{"id":"sFDlXqUwpj1P"}},{"cell_type":"code","source":["df[['tweet', 'tweet_clean']].values[0:5] "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1mhSp2upX2d","executionInfo":{"status":"ok","timestamp":1650961080753,"user_tz":-120,"elapsed":7,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"d35b50a4-fa47-4696-c661-b3a1039aa995"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([['@USER She should ask a few native Americans what their take on this is.',\n","        '@user she should ask a few native americans what their take on this is.'],\n","       ['@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL',\n","        '@user @user go home you are drunk! @user maga trump2020 oncoming_fistUnited_Statesoncoming_fist url'],\n","       ['Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT',\n","        'amazon is investigating chinese employees who are selling internal data to thirdparty sellers looking for an edge in the competitive marketplace. url amazon maga kag china tcot'],\n","       ['@USER Someone should\\'veTaken\" this piece of shit to a volcano. 😂\"',\n","        '@user someone shouldvetaken this piece of shit to a volcano. face_with_tears_of_joy'],\n","       ['@USER @USER Obama wanted liberals &amp; illegals to move into red states',\n","        '@user @user obama wanted liberals amp; illegals to move into red states']],\n","      dtype=object)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["**Text Normalization : Lemmatization and Tokenization**\n","\n","To normalize the tweet text, we apply lemmatizer and tokenizer. I will use Spacy to lemmatize but will rely on Tweet Tokenizer of NLTK to tokenize the tweets. "],"metadata":{"id":"ZtO8eSUckRPv"}},{"cell_type":"code","source":["# !pip install -U spacy\n","# !python3 -m spacy download en_core_web_sm\n","\n","import spacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","spacy.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xCisHT6ZJpg6","executionInfo":{"status":"ok","timestamp":1650961083707,"user_tz":-120,"elapsed":1495,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"780096eb-3772-4743-f186-5bed6322c622"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.2.4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# function to get lemmas from spacy nlp \n","\n","def get_lemmas (tweet):\n","    tweets = nlp(tweet)\n","    return \" \".join([token.lemma_ for token in tweets])"],"metadata":{"id":"mec0Kj40JpnM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to get POS information\n","\n","def get_pos (tweet):\n","    tweets = nlp(tweet)\n","    return \" \".join([token.pos_ for token in tweets])"],"metadata":{"id":"WQMuRdKBertv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tweets = df.tweet_clean.values\n","tweet_lemmas = [get_lemmas(tweet) for tweet in tweets]\n","tweet_pos = [get_pos(tweet) for tweet in tweets]\n","df['tweet_lemmas'] = tweet_lemmas\n","df['tweet_pos'] = tweet_pos #maybe need it for modelling?"],"metadata":{"id":"saIkoMMzPEWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"id":"3HaTkkiDQQOo","executionInfo":{"status":"ok","timestamp":1650961386954,"user_tz":-120,"elapsed":24,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"ea39f037-5b09-4074-94b1-4474a22e9f6a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   tweet  offensive  \\\n","id                                                                    \n","86426  @USER She should ask a few native Americans wh...          1   \n","90194  @USER @USER Go home you’re drunk!!! @USER #MAG...          1   \n","16820  Amazon is investigating Chinese employees who ...          0   \n","62688  @USER Someone should'veTaken\" this piece of sh...          1   \n","43605  @USER @USER Obama wanted liberals &amp; illega...          0   \n","97670                  @USER Liberals are all Kookoo !!!          1   \n","77444                   @USER @USER Oh noes! Tough shit.          1   \n","52415  @USER was literally just talking about this lo...          1   \n","45157                         @USER Buy more icecream!!!          0   \n","13384  @USER Canada doesn’t need another CUCK! We alr...          1   \n","\n","                                             tweet_clean  \\\n","id                                                         \n","86426  @user she should ask a few native americans wh...   \n","90194  @user @user go home you are drunk! @user maga ...   \n","16820  amazon is investigating chinese employees who ...   \n","62688  @user someone shouldvetaken this piece of shit...   \n","43605  @user @user obama wanted liberals amp; illegal...   \n","97670                    @user liberals are all kookoo !   \n","77444                   @user @user oh noes! tough shit.   \n","52415  @user was literally just talking about this lo...   \n","45157                           @user buy more icecream!   \n","13384  @user canada does not need another cuck! we al...   \n","\n","                                            tweet_lemmas  \\\n","id                                                         \n","86426  @user -PRON- should ask a few native americans...   \n","90194  @user @user go home -PRON- be drunk ! @user ma...   \n","16820  amazon be investigate chinese employee who be ...   \n","62688  @user someone shouldvetaken this piece of shit...   \n","43605  @user @user obama want liberal amp ; illegal t...   \n","97670                      @user liberal be all kookoo !   \n","77444                   @user @user oh no ! tough shit .   \n","52415  @user be literally just talk about this lol al...   \n","45157                          @user buy more icecream !   \n","13384  @user canada do not need another cuck ! -PRON-...   \n","\n","                                               tweet_pos  \n","id                                                        \n","86426  X PRON VERB VERB DET ADJ ADJ PROPN PRON DET VE...  \n","90194  X PUNCT VERB ADV PRON AUX ADJ PUNCT X PROPN PR...  \n","16820  PROPN AUX VERB ADJ NOUN PRON AUX VERB ADJ NOUN...  \n","62688  PUNCT PRON VERB DET NOUN ADP NOUN ADP DET NOUN...  \n","43605  PUNCT PUNCT PROPN VERB NOUN VERB PUNCT NOUN PA...  \n","97670                        ADJ NOUN AUX DET VERB PUNCT  \n","77444                 X X INTJ NOUN PUNCT ADJ NOUN PUNCT  \n","52415  PROPN AUX ADV ADV VERB ADP DET NOUN DET ADJ NO...  \n","45157                              X VERB ADJ NOUN PUNCT  \n","13384  PROPN PROPN AUX PART VERB DET NOUN PUNCT PRON ...  "],"text/html":["\n","  <div id=\"df-9e86f473-0aec-4521-a8c4-c9b1cb407356\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>offensive</th>\n","      <th>tweet_clean</th>\n","      <th>tweet_lemmas</th>\n","      <th>tweet_pos</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>86426</th>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>1</td>\n","      <td>@user she should ask a few native americans wh...</td>\n","      <td>@user -PRON- should ask a few native americans...</td>\n","      <td>X PRON VERB VERB DET ADJ ADJ PROPN PRON DET VE...</td>\n","    </tr>\n","    <tr>\n","      <th>90194</th>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>1</td>\n","      <td>@user @user go home you are drunk! @user maga ...</td>\n","      <td>@user @user go home -PRON- be drunk ! @user ma...</td>\n","      <td>X PUNCT VERB ADV PRON AUX ADJ PUNCT X PROPN PR...</td>\n","    </tr>\n","    <tr>\n","      <th>16820</th>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>0</td>\n","      <td>amazon is investigating chinese employees who ...</td>\n","      <td>amazon be investigate chinese employee who be ...</td>\n","      <td>PROPN AUX VERB ADJ NOUN PRON AUX VERB ADJ NOUN...</td>\n","    </tr>\n","    <tr>\n","      <th>62688</th>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>1</td>\n","      <td>@user someone shouldvetaken this piece of shit...</td>\n","      <td>@user someone shouldvetaken this piece of shit...</td>\n","      <td>PUNCT PRON VERB DET NOUN ADP NOUN ADP DET NOUN...</td>\n","    </tr>\n","    <tr>\n","      <th>43605</th>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>0</td>\n","      <td>@user @user obama wanted liberals amp; illegal...</td>\n","      <td>@user @user obama want liberal amp ; illegal t...</td>\n","      <td>PUNCT PUNCT PROPN VERB NOUN VERB PUNCT NOUN PA...</td>\n","    </tr>\n","    <tr>\n","      <th>97670</th>\n","      <td>@USER Liberals are all Kookoo !!!</td>\n","      <td>1</td>\n","      <td>@user liberals are all kookoo !</td>\n","      <td>@user liberal be all kookoo !</td>\n","      <td>ADJ NOUN AUX DET VERB PUNCT</td>\n","    </tr>\n","    <tr>\n","      <th>77444</th>\n","      <td>@USER @USER Oh noes! Tough shit.</td>\n","      <td>1</td>\n","      <td>@user @user oh noes! tough shit.</td>\n","      <td>@user @user oh no ! tough shit .</td>\n","      <td>X X INTJ NOUN PUNCT ADJ NOUN PUNCT</td>\n","    </tr>\n","    <tr>\n","      <th>52415</th>\n","      <td>@USER was literally just talking about this lo...</td>\n","      <td>1</td>\n","      <td>@user was literally just talking about this lo...</td>\n","      <td>@user be literally just talk about this lol al...</td>\n","      <td>PROPN AUX ADV ADV VERB ADP DET NOUN DET ADJ NO...</td>\n","    </tr>\n","    <tr>\n","      <th>45157</th>\n","      <td>@USER Buy more icecream!!!</td>\n","      <td>0</td>\n","      <td>@user buy more icecream!</td>\n","      <td>@user buy more icecream !</td>\n","      <td>X VERB ADJ NOUN PUNCT</td>\n","    </tr>\n","    <tr>\n","      <th>13384</th>\n","      <td>@USER Canada doesn’t need another CUCK! We alr...</td>\n","      <td>1</td>\n","      <td>@user canada does not need another cuck! we al...</td>\n","      <td>@user canada do not need another cuck ! -PRON-...</td>\n","      <td>PROPN PROPN AUX PART VERB DET NOUN PUNCT PRON ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e86f473-0aec-4521-a8c4-c9b1cb407356')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9e86f473-0aec-4521-a8c4-c9b1cb407356 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9e86f473-0aec-4521-a8c4-c9b1cb407356');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["**Additional Features**\n","\n","The first classification model, a SVM classifier will take Tf-Idf weighted vectors of the text as input. However, because in this model I am not allowed to use embeddings or transformers, I will add additional feature vectors to my model to take semantics into account when classifying a tweet as offensive. \n","\n","The additional features represent emotion (through NRC lexicon) and hate speech (through hate speech lexicon of Bassignana et al. (2018)). The traditional model to detect offensive tweets follows the work of Markov and Daelemans (2021). \n","\n","<br>\n","\n","*Emotion classification of tweets using NRC Lexicon*"],"metadata":{"id":"m8G52aOcTvPA"}},{"cell_type":"code","source":["!pip install NRCLex\n","!python -m textblob.download_corpora\n","from nrclex import NRCLex\n"],"metadata":{"id":"ZPhHo_2dVUE7","executionInfo":{"status":"ok","timestamp":1650961396096,"user_tz":-120,"elapsed":9150,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6abbc0b8-f575-455c-f7a4-75b11f4791a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting NRCLex\n","  Downloading NRCLex-3.0.0.tar.gz (396 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |█████                           | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 348 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 358 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 368 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 378 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 389 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 396 kB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from NRCLex) (0.15.3)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob->NRCLex) (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob->NRCLex) (1.15.0)\n","Building wheels for collected packages: NRCLex\n","  Building wheel for NRCLex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for NRCLex: filename=NRCLex-3.0.0-py3-none-any.whl size=43329 sha256=b04f8a4d9d54bdccb32b71f34866090097eaf27ae7c21e33f86487915718a73a\n","  Stored in directory: /root/.cache/pip/wheels/af/2c/9c/dfa19d1b65326c520b32850a9311f6d4eda679ac04dba26081\n","Successfully built NRCLex\n","Installing collected packages: NRCLex\n","Successfully installed NRCLex-3.0.0\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/conll2000.zip.\n","[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n","Finished.\n"]}]},{"cell_type":"code","source":["def return_emotions (tweet):\n","    emotion = NRCLex(tweet)\n","    return emotion.affect_list"],"metadata":{"id":"CCmKS1CEVUH2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check\n","print(tweets[67])\n","print(return_emotions(tweets[67]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ulu-l81VUKW","executionInfo":{"status":"ok","timestamp":1650961396097,"user_tz":-120,"elapsed":7,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"209d7684-6ddc-4b0e-8942-409483990c6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["@user you are so straight forword manOK_hand i saw you in dance dewwane and you are just talk free ky ap kitnay porrany ho industry mein and i really like you are this quality that you even gather with you are seniorgreen_heart artist love for manmarziyaan cowboy_hat_facethumbs_up\n","['joy', 'positive', 'trust', 'positive', 'joy', 'positive']\n"]}]},{"cell_type":"code","source":["tweet_emotions = [return_emotions(tweet) for tweet in tweets]\n","df['tweet_emotions'] = tweet_emotions\n","df['tweet_emotions'] = df['tweet_emotions'].apply(lambda x: ' '.join(dict.fromkeys(x).keys()))"],"metadata":{"id":"ljrAhiVBYgk8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","<br>\n","\n","*Using insult words lexicon we can detect abusive words in tweets and take the TDIDF vectors of these words as input to include semantics in the model.*\n","\n","The insults lexicon is taken from the research of Bassignana et al. (2018) from the following GitHub repository: https://github.com/bgmartins/hate-speech-lexicons\n","\n","\n","\n"],"metadata":{"id":"MzLXndOSZGpb"}},{"cell_type":"code","source":["lexicon_path = 'drive/MyDrive/NLP_Final_Assignment/data/abusive_words.txt'\n","insults_lexicon = pd.read_csv(lexicon_path, sep='\\t', header=None)\n","insults_lexicon.columns = ['insults']\n","insults_lexicon.head(10)"],"metadata":{"id":"1pkQo5YEZGIr","executionInfo":{"status":"ok","timestamp":1650961411407,"user_tz":-120,"elapsed":678,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"colab":{"base_uri":"https://localhost:8080/","height":363},"outputId":"39629a02-224e-438b-80be-cd2070a4af6c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           insults\n","0           lummox\n","1      cross-breed\n","2         dumbbell\n","3              bum\n","4          vagrant\n","5          rentboy\n","6         rent-boy\n","7      sonuvabitch\n","8             rats\n","9  sons of bitches"],"text/html":["\n","  <div id=\"df-f887c798-3cce-4d2f-8e08-5c4e380ad13f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>insults</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>lummox</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cross-breed</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dumbbell</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bum</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>vagrant</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>rentboy</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>rent-boy</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>sonuvabitch</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>rats</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>sons of bitches</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f887c798-3cce-4d2f-8e08-5c4e380ad13f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f887c798-3cce-4d2f-8e08-5c4e380ad13f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f887c798-3cce-4d2f-8e08-5c4e380ad13f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# Unique insults\n","insult_list = list(insults_lexicon['insults'].unique())\n","\n","# Extract the words if there is an exact match \n","df['insult_match'] = df['tweet_clean'].str.findall(r'\\b(' + '|'.join(insult_list) + r')\\b')\n","df['insult_match'] = [' '.join(map(str, l)) for l in df['insult_match']]\n","\n","\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"1R-wYwsKBJu3","executionInfo":{"status":"ok","timestamp":1650961413213,"user_tz":-120,"elapsed":1812,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"7221ef3f-4f0e-422b-b2ae-2f27b2f9cad9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   tweet  offensive  \\\n","id                                                                    \n","86426  @USER She should ask a few native Americans wh...          1   \n","90194  @USER @USER Go home you’re drunk!!! @USER #MAG...          1   \n","16820  Amazon is investigating Chinese employees who ...          0   \n","62688  @USER Someone should'veTaken\" this piece of sh...          1   \n","43605  @USER @USER Obama wanted liberals &amp; illega...          0   \n","\n","                                             tweet_clean  \\\n","id                                                         \n","86426  @user she should ask a few native americans wh...   \n","90194  @user @user go home you are drunk! @user maga ...   \n","16820  amazon is investigating chinese employees who ...   \n","62688  @user someone shouldvetaken this piece of shit...   \n","43605  @user @user obama wanted liberals amp; illegal...   \n","\n","                                            tweet_lemmas  \\\n","id                                                         \n","86426  @user -PRON- should ask a few native americans...   \n","90194  @user @user go home -PRON- be drunk ! @user ma...   \n","16820  amazon be investigate chinese employee who be ...   \n","62688  @user someone shouldvetaken this piece of shit...   \n","43605  @user @user obama want liberal amp ; illegal t...   \n","\n","                                               tweet_pos  \\\n","id                                                         \n","86426  X PRON VERB VERB DET ADJ ADJ PROPN PRON DET VE...   \n","90194  X PUNCT VERB ADV PRON AUX ADJ PUNCT X PROPN PR...   \n","16820  PROPN AUX VERB ADJ NOUN PRON AUX VERB ADJ NOUN...   \n","62688  PUNCT PRON VERB DET NOUN ADP NOUN ADP DET NOUN...   \n","43605  PUNCT PUNCT PROPN VERB NOUN VERB PUNCT NOUN PA...   \n","\n","                             tweet_emotions insult_match  \n","id                                                        \n","86426                                                     \n","90194                                                     \n","16820                                                     \n","62688  anger disgust negative fear surprise         shit  \n","43605                                                     "],"text/html":["\n","  <div id=\"df-6ab9472c-bf1a-4966-b350-d9ffd817f741\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>offensive</th>\n","      <th>tweet_clean</th>\n","      <th>tweet_lemmas</th>\n","      <th>tweet_pos</th>\n","      <th>tweet_emotions</th>\n","      <th>insult_match</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>86426</th>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>1</td>\n","      <td>@user she should ask a few native americans wh...</td>\n","      <td>@user -PRON- should ask a few native americans...</td>\n","      <td>X PRON VERB VERB DET ADJ ADJ PROPN PRON DET VE...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>90194</th>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>1</td>\n","      <td>@user @user go home you are drunk! @user maga ...</td>\n","      <td>@user @user go home -PRON- be drunk ! @user ma...</td>\n","      <td>X PUNCT VERB ADV PRON AUX ADJ PUNCT X PROPN PR...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>16820</th>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>0</td>\n","      <td>amazon is investigating chinese employees who ...</td>\n","      <td>amazon be investigate chinese employee who be ...</td>\n","      <td>PROPN AUX VERB ADJ NOUN PRON AUX VERB ADJ NOUN...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>62688</th>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>1</td>\n","      <td>@user someone shouldvetaken this piece of shit...</td>\n","      <td>@user someone shouldvetaken this piece of shit...</td>\n","      <td>PUNCT PRON VERB DET NOUN ADP NOUN ADP DET NOUN...</td>\n","      <td>anger disgust negative fear surprise</td>\n","      <td>shit</td>\n","    </tr>\n","    <tr>\n","      <th>43605</th>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>0</td>\n","      <td>@user @user obama wanted liberals amp; illegal...</td>\n","      <td>@user @user obama want liberal amp ; illegal t...</td>\n","      <td>PUNCT PUNCT PROPN VERB NOUN VERB PUNCT NOUN PA...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ab9472c-bf1a-4966-b350-d9ffd817f741')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ab9472c-bf1a-4966-b350-d9ffd817f741 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ab9472c-bf1a-4966-b350-d9ffd817f741');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["df.offensive.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dEPu3kgy0b7U","executionInfo":{"status":"ok","timestamp":1650961413215,"user_tz":-120,"elapsed":23,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"cfb2f941-3c9f-466a-adde-b2fd9763dc7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    8817\n","1    4395\n","Name: offensive, dtype: int64"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["df.insult_match.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3cFyr4uIz8Mi","executionInfo":{"status":"ok","timestamp":1650961413216,"user_tz":-120,"elapsed":19,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"bbb3eda6-fd3c-47b5-aa11-8ea39786adcf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                         12054\n","shit                                       327\n","stupid                                      91\n","idiot                                       44\n","dumb                                        35\n","                                         ...  \n","shit foolish                                 1\n","asshole shit                                 1\n","ignorant fool ignorant ignorant idiot        1\n","idiot retard                                 1\n","midget                                       1\n","Name: insult_match, Length: 168, dtype: int64"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["df[df['offensive'] > 0].insult_match.value_counts() \n","# from a quick look we can see that majority of the tweets with an insult word\n","# are under offensive label but majority of offensive tweets do not have \n","# insult words (3516 out of 4395)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO8a8Qjaz8O_","executionInfo":{"status":"ok","timestamp":1650961413216,"user_tz":-120,"elapsed":16,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"43b57b1a-8d9a-4836-c0ac-19edee9b2530"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      3516\n","shit                   288\n","stupid                  83\n","idiot                   42\n","ignorant                27\n","                      ... \n","nonsense stupid          1\n","idiots stupidity         1\n","fool ignorant fool       1\n","quack                    1\n","dense                    1\n","Name: insult_match, Length: 142, dtype: int64"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["df[df['offensive'] == 0].insult_match.value_counts() \n","# out of 8817 non offensive tweets, \n","# 8539 have no offensive word according to the lexicon"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-sFUph2z8SW","executionInfo":{"status":"ok","timestamp":1650961413217,"user_tz":-120,"elapsed":14,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"0965f9b5-29ec-4e97-8214-90711d9824d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                8538\n","shit              39\n","mark              17\n","simple            12\n","nonsense          12\n","                ... \n","shit foolish       1\n","fooled             1\n","rabble             1\n","chatterbox         1\n","midget             1\n","Name: insult_match, Length: 86, dtype: int64"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"AsoNEbj7Jppi","executionInfo":{"status":"ok","timestamp":1650961413217,"user_tz":-120,"elapsed":11,"user":{"displayName":"Elif Kılık","userId":"11782822261414782154"}},"outputId":"6acb3921-9b99-4075-dc5f-f26bb8a456b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   tweet  offensive  \\\n","id                                                                    \n","86426  @USER She should ask a few native Americans wh...          1   \n","90194  @USER @USER Go home you’re drunk!!! @USER #MAG...          1   \n","16820  Amazon is investigating Chinese employees who ...          0   \n","62688  @USER Someone should'veTaken\" this piece of sh...          1   \n","43605  @USER @USER Obama wanted liberals &amp; illega...          0   \n","\n","                                             tweet_clean  \\\n","id                                                         \n","86426  @user she should ask a few native americans wh...   \n","90194  @user @user go home you are drunk! @user maga ...   \n","16820  amazon is investigating chinese employees who ...   \n","62688  @user someone shouldvetaken this piece of shit...   \n","43605  @user @user obama wanted liberals amp; illegal...   \n","\n","                                            tweet_lemmas  \\\n","id                                                         \n","86426  @user -PRON- should ask a few native americans...   \n","90194  @user @user go home -PRON- be drunk ! @user ma...   \n","16820  amazon be investigate chinese employee who be ...   \n","62688  @user someone shouldvetaken this piece of shit...   \n","43605  @user @user obama want liberal amp ; illegal t...   \n","\n","                                               tweet_pos  \\\n","id                                                         \n","86426  X PRON VERB VERB DET ADJ ADJ PROPN PRON DET VE...   \n","90194  X PUNCT VERB ADV PRON AUX ADJ PUNCT X PROPN PR...   \n","16820  PROPN AUX VERB ADJ NOUN PRON AUX VERB ADJ NOUN...   \n","62688  PUNCT PRON VERB DET NOUN ADP NOUN ADP DET NOUN...   \n","43605  PUNCT PUNCT PROPN VERB NOUN VERB PUNCT NOUN PA...   \n","\n","                             tweet_emotions insult_match  \n","id                                                        \n","86426                                                     \n","90194                                                     \n","16820                                                     \n","62688  anger disgust negative fear surprise         shit  \n","43605                                                     "],"text/html":["\n","  <div id=\"df-935eb2dd-3bd4-43b9-9107-90b847baed2d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>offensive</th>\n","      <th>tweet_clean</th>\n","      <th>tweet_lemmas</th>\n","      <th>tweet_pos</th>\n","      <th>tweet_emotions</th>\n","      <th>insult_match</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>86426</th>\n","      <td>@USER She should ask a few native Americans wh...</td>\n","      <td>1</td>\n","      <td>@user she should ask a few native americans wh...</td>\n","      <td>@user -PRON- should ask a few native americans...</td>\n","      <td>X PRON VERB VERB DET ADJ ADJ PROPN PRON DET VE...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>90194</th>\n","      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n","      <td>1</td>\n","      <td>@user @user go home you are drunk! @user maga ...</td>\n","      <td>@user @user go home -PRON- be drunk ! @user ma...</td>\n","      <td>X PUNCT VERB ADV PRON AUX ADJ PUNCT X PROPN PR...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>16820</th>\n","      <td>Amazon is investigating Chinese employees who ...</td>\n","      <td>0</td>\n","      <td>amazon is investigating chinese employees who ...</td>\n","      <td>amazon be investigate chinese employee who be ...</td>\n","      <td>PROPN AUX VERB ADJ NOUN PRON AUX VERB ADJ NOUN...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>62688</th>\n","      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n","      <td>1</td>\n","      <td>@user someone shouldvetaken this piece of shit...</td>\n","      <td>@user someone shouldvetaken this piece of shit...</td>\n","      <td>PUNCT PRON VERB DET NOUN ADP NOUN ADP DET NOUN...</td>\n","      <td>anger disgust negative fear surprise</td>\n","      <td>shit</td>\n","    </tr>\n","    <tr>\n","      <th>43605</th>\n","      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n","      <td>0</td>\n","      <td>@user @user obama wanted liberals amp; illegal...</td>\n","      <td>@user @user obama want liberal amp ; illegal t...</td>\n","      <td>PUNCT PUNCT PROPN VERB NOUN VERB PUNCT NOUN PA...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-935eb2dd-3bd4-43b9-9107-90b847baed2d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-935eb2dd-3bd4-43b9-9107-90b847baed2d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-935eb2dd-3bd4-43b9-9107-90b847baed2d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["# Writing this dataset in a csv file to use for modelling \n","\n","writing_path = 'drive/MyDrive/NLP_Final_Assignment/data/df_preprocessed.csv'\n","\n","df.to_csv(writing_path, encoding='utf-8', index=True)\n"],"metadata":{"id":"2Ch_J8_C2PqO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VfyZCWRQB7St"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**References**\n","\n","Bassignana, E., Basile, V., & Patti, V. (2018). Hurtlex: A multilingual lexicon of words to hurt. In 5th Italian Conference on Computational Linguistics, CLiC-it 2018 (Vol. 2253, pp. 1-6). CEUR-WS.\n","\n","De Smedt, T., Voué, P., Jaki, S., Röttcher, M., & De Pauw, G. (2020). Profanity & offensive words (POW).\n","\n","Markov, I., & Daelemans, W. (2021, June). Improving Cross-Domain Hate Speech Detection by Reducing the False Positive Rate. In Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda (pp. 17-22).\n","\n","Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., & Kumar, R. (2019). Predicting the type and target of offensive posts in social media. arXiv preprint arXiv:1902.09666.\n"],"metadata":{"id":"c8_SVnkvzi8e"}},{"cell_type":"code","source":[""],"metadata":{"id":"8IgZt2UDzlwk"},"execution_count":null,"outputs":[]}]}